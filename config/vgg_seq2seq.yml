vocab_size: 233
vocab: models/definitions/vocab.yml
device: 'cuda'
weights: models/weights/seq2seq/base/base_s2s.pth
# weights: models/weights/seq2seq/vtp/2110191721/2110200347.pth
# weights: models/weights/seq2seq/2110191721/checkpoint.pth
# weights: models/weights/seq2seq/vtp/2110201652/2110202130.pth
# weights: models/weights/seq2seq/general/2110261418/checkpoint.pth
# weights: models/weights/seq2seq/general/2110261430/2110270839.pth
# weights: models/weights/seq2seq/general/2110261430/2110262029.pth
# weights: models/weights/seq2seq/general/2110261430/2110261600.pth
# weights: models/weights/seq2seq/vtp/2110191721/2110200347.pth
# weights: models/weights/seq2seq/vtp/2110201652/2110202130.pth
# weights: models/weights/seq2seq/vtp/2110270915/2110270923.pth
# weights: models/weights/seq2seq/general/2110271457/2110272340.pth
# weights: models/weights/seq2seq/general/2110271457/2110272150.pth
# weights: models/weights/seq2seq/DKKD/2111111715/2111112333.pth
# weights: models/weights/seq2seq/DKKD/2111111217/2111131207.pth
# weights: models/weights/seq2seq/DKKD/2111111715/2111130608.pth
# weights: models/weights/seq2seq/DKKD/2111130608.pth

save_file:
    excel: result/DKKD/2111130608.xlsx
    text: result/DKKD/2111130608.txt

trainer:
    batch_size: 16
    display_cycle: 100
    valid_cycle: 1000
    iters: 200000
    weight_dir: models/weights/seq2seq/DKKD/

dataset:    
    name: 'DKKD'
    data_root: ./dataset/images/DKKD/
    train_annotation: ./dataset/annotation/DKKD/train.txt
    valid_annotation: ./dataset/annotation/DKKD/test.txt
    test_annotation: ./dataset/annotation/DKKD/test.txt
    expected_height: 32
    image_min_width: 32
    image_max_width: 2048

seq_modeling: seq2seq
transformer:
    encoder_hidden: 256
    decoder_hidden: 256
    image_channel: 256
    decoder_embedded: 256
    dropout: 0.1

optimizer:
    max_lr: 0.0003
    pct_start: 0.1

dataloader:
    num_workers: 4
    pin_memory: True

aug:
    image_aug: True
    masked_language_model: True

backbone: vgg19
cnn_args:
    pretrained: False
    ss: [[2, 2],
         [2, 2],
         [2, 1],
         [2, 1],
         [2, 1]]
    ks: [[2, 2],
         [2, 2],
         [2, 1],
         [2, 1],
         [2, 1]]
    hidden: 256
    dropout: 0.1